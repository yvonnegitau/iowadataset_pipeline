[2022-03-18 21:51:08,545] {taskinstance.py:1037} INFO - Dependencies all met for <TaskInstance: EL_dag.local_to_gcs_task manual__2022-03-18T21:51:04.166915+00:00 [queued]>
[2022-03-18 21:51:08,551] {taskinstance.py:1037} INFO - Dependencies all met for <TaskInstance: EL_dag.local_to_gcs_task manual__2022-03-18T21:51:04.166915+00:00 [queued]>
[2022-03-18 21:51:08,551] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-03-18 21:51:08,552] {taskinstance.py:1244} INFO - Starting attempt 1 of 2
[2022-03-18 21:51:08,552] {taskinstance.py:1245} INFO - 
--------------------------------------------------------------------------------
[2022-03-18 21:51:08,559] {taskinstance.py:1264} INFO - Executing <Task(PythonOperator): local_to_gcs_task> on 2022-03-18 21:51:04.166915+00:00
[2022-03-18 21:51:08,562] {standard_task_runner.py:52} INFO - Started process 308 to run task
[2022-03-18 21:51:08,565] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'EL_dag', 'local_to_gcs_task', 'manual__2022-03-18T21:51:04.166915+00:00', '--job-id', '38', '--raw', '--subdir', 'DAGS_FOLDER/extract_load_dags.py', '--cfg-path', '/tmp/tmp54qjojgd', '--error-file', '/tmp/tmp86pqjpv7']
[2022-03-18 21:51:08,566] {standard_task_runner.py:77} INFO - Job 38: Subtask local_to_gcs_task
[2022-03-18 21:51:08,616] {logging_mixin.py:109} INFO - Running <TaskInstance: EL_dag.local_to_gcs_task manual__2022-03-18T21:51:04.166915+00:00 [running]> on host d6b2ec1ac43c
[2022-03-18 21:51:08,647] {logging_mixin.py:109} WARNING - /usr/local/lib/python3.9/site-packages/airflow/utils/context.py:156 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-03-18 21:51:08,670] {taskinstance.py:1429} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=EL_dag
AIRFLOW_CTX_TASK_ID=local_to_gcs_task
AIRFLOW_CTX_EXECUTION_DATE=2022-03-18T21:51:04.166915+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-03-18T21:51:04.166915+00:00
[2022-03-18 21:51:08,682] {taskinstance.py:1718} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1334, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1460, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1516, in _execute_task
    result = execute_callable(context=context)
  File "/usr/local/lib/python3.9/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/usr/local/lib/python3.9/site-packages/airflow/operators/python.py", line 188, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/iowa/airflow/dags/extract_load.py", line 47, in upload_to_gcs
    blob.upload_from_filename(local_file)
  File "/usr/local/lib/python3.9/site-packages/google/cloud/storage/blob.py", line 2720, in upload_from_filename
    with open(filename, "rb") as file_obj:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data_2022-03.parquet'
[2022-03-18 21:51:08,695] {taskinstance.py:1272} INFO - Marking task as UP_FOR_RETRY. dag_id=EL_dag, task_id=local_to_gcs_task, execution_date=20220318T215104, start_date=20220318T215108, end_date=20220318T215108
[2022-03-18 21:51:08,703] {standard_task_runner.py:89} ERROR - Failed to execute job 38 for task local_to_gcs_task
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/usr/local/lib/python3.9/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/usr/local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/usr/local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 180, in _run_raw_task
    ti._run_raw_task(
  File "/usr/local/lib/python3.9/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1334, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1460, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1516, in _execute_task
    result = execute_callable(context=context)
  File "/usr/local/lib/python3.9/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/usr/local/lib/python3.9/site-packages/airflow/operators/python.py", line 188, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/iowa/airflow/dags/extract_load.py", line 47, in upload_to_gcs
    blob.upload_from_filename(local_file)
  File "/usr/local/lib/python3.9/site-packages/google/cloud/storage/blob.py", line 2720, in upload_from_filename
    with open(filename, "rb") as file_obj:
FileNotFoundError: [Errno 2] No such file or directory: '../data/data_2022-03.parquet'
[2022-03-18 21:51:08,737] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-03-18 21:51:08,763] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
